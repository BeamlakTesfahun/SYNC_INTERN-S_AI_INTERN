{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6348501",
   "metadata": {},
   "source": [
    "# SYNC INTERN'S\n",
    "Beamlak Tesfahun - Artificial Intelligence Intern\n",
    "\n",
    "Task 1 - Plant Disease Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4cf49",
   "metadata": {},
   "source": [
    "# Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10032cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "import itertools\n",
    "import cv2\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pathlib\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print ('Modules have successfully been loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b070f238",
   "metadata": {},
   "source": [
    "# Define Required Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c261706",
   "metadata": {},
   "source": [
    "Function to create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa65c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make filepath--label dataframe\n",
    "def filepath_label_data_frame(dataset_directory):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    docs = os.listdir(dataset_directory)\n",
    "    for doc in docs:\n",
    "        doc_path = os.path.join(dataset_directory, doc)\n",
    "        files = os.listdir(doc_path)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(doc_path, file)\n",
    "            filepaths.append(file_path)\n",
    "            labels.append(doc)\n",
    "    # Concatenate data paths with labels into one dataframe\n",
    "    filepath_series = pd.Series(filepaths, name= 'filepaths')\n",
    "    label_series = pd.Series(labels, name='labels')\n",
    "    d_frame = pd.concat([filepath_series, label_series], axis= 1) # axis=1: to display the series side by side\n",
    "    return d_frame\n",
    "\n",
    "# Function to split dataframe to train, validation, and test \n",
    "def split_dataset(dataset_directory):\n",
    "    # train dataframe\n",
    "    data_frame = filepath_label_data_frame(dataset_directory)\n",
    "    s = data_frame['labels']                                                \n",
    "    train_data_frame, dummy_data_frame = train_test_split(data_frame,  train_size= 0.8, shuffle= True, random_state= 42, stratify= s)\n",
    "\n",
    "    # validate and test dataframe\n",
    "    s = dummy_data_frame['labels']\n",
    "    valid_data_frame, test_data_frame = train_test_split(dummy_data_frame,  train_size= 0.5, shuffle= True, random_state= 42, stratify= s)\n",
    "    # display train, validate, and test dataframe\n",
    "    # sample to pull 2 random rows\n",
    "    print('Train dataframe')\n",
    "    display(train_data_frame.sample(2))\n",
    "    print('Validation dataframe')\n",
    "    display(valid_data_frame.sample(2))\n",
    "    print('Test dataframe')\n",
    "    display(test_data_frame.sample(2))\n",
    "    return train_data_frame, valid_data_frame, test_data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23467036",
   "metadata": {},
   "source": [
    "Function to generate images from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30558bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create generators for given dataframes \n",
    "def create_img_generators(train_df, valid_df, test_df, batch_size):\n",
    "    # Defining model parameters\n",
    "    img_size = (224, 224)\n",
    "    channels = 3      \n",
    "    img_shape = (224, 224, 3)\n",
    "\n",
    "    # Defining values for test_batch_size and test_steps\n",
    "    test_df_length = len(test_df) # Fetch the length of test dataframe   \n",
    "    test_batch_size = 8               \n",
    "    test_steps = test_df_length // test_batch_size\n",
    "    \n",
    "\n",
    "    # This function is used in ImageDataGenerator for data augmentation, it returns image as it is\n",
    "    def image(img):\n",
    "        return img\n",
    "    # Data augmentation\n",
    "    t_gen = ImageDataGenerator(preprocessing_function= image, horizontal_flip= True)              \n",
    "    v_gen = ImageDataGenerator(preprocessing_function= image)                    \n",
    "\n",
    "    train_gen = t_gen.flow_from_dataframe(dataframe = train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',     \n",
    "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "\n",
    "    valid_gen = v_gen.flow_from_dataframe(dataframe = valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "    # shuffle is set to false, use batch_size of 8\n",
    "    test_gen = v_gen.flow_from_dataframe(dataframe = test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)       \n",
    "\n",
    "    return train_gen, valid_gen, test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e13d0",
   "metadata": {},
   "source": [
    "Function to display data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes the data generator and show sample of the images\n",
    "def show_samples(generator):\n",
    "    # return classes , images to be displayed\n",
    "    g_dict = generator.class_indices        \n",
    "    classes = list(g_dict.keys())     \n",
    "    images, labels = next(generator)  \n",
    "\n",
    "    # calculate number of displayed samples\n",
    "    length = len(labels)       \n",
    "    sample = min(length, 20)    \n",
    "\n",
    "    plt.figure(figsize= (25, 20))\n",
    "\n",
    "    for i in range(sample):\n",
    "        # show image\n",
    "        plt.subplot(4, 5, (i + 1))\n",
    "        image = images[i] / 255 # scale pixels\n",
    "        plt.imshow(image)\n",
    "        # get class of image\n",
    "        index = np.argmax(labels[i])  \n",
    "        class_name = classes[index]   \n",
    "        plt.title(class_name, color= 'Red', fontsize= 14)\n",
    "        plt.subplots_adjust(hspace=0.1, wspace=0.6)       \n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6ce4f",
   "metadata": {},
   "source": [
    "# Get Generators and Splitted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615903e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = r'C:\\Users\\Tesfahun Sahilu\\Desktop\\Coursera\\plantvillage dataset\\color' # Reading data\n",
    "# Get splitted data\n",
    "train_df, valid_df, test_df = split_dataset(dataset_directory)\n",
    "\n",
    "# Get generators\n",
    "train_gen, valid_gen, test_gen = create_img_generators(train_df, valid_df, test_df, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a1a0a",
   "metadata": {},
   "source": [
    "# Display Image Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32fdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(train_gen) # call function show_samples to visualize image samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ceeb2",
   "metadata": {},
   "source": [
    "# Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28cf4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks: stop model training after specfic time, stop training if there is no improvement in accuracy and so on\n",
    "# Defining callback parameters\n",
    "batch_size = 32 # the number of samples processed before model is updated  \n",
    "epochs = 10               \n",
    "lr_patience = 1 # the number of epochs to wait before early stop if value does not improve\n",
    "early_stop_patience = 2 # number of epochs to wait before stopping training if monitored value does not improve \n",
    "factor = 0.5 # factor to reduce lr by\n",
    "\n",
    "# Define callbacks\n",
    "# Early Stopping: stop the training as soon as the model starts overfitting\n",
    "# to look for the performance of the training and validation set \n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=early_stop_patience,\n",
    "                           verbose=1, \n",
    "                           mode='min', \n",
    "                           baseline=None,\n",
    "                           restore_best_weights=True\n",
    "                          )\n",
    "# Reduce learning rate when metric has stopped improving\n",
    "lr_reduction_on_plateau = ReduceLROnPlateau(monitor='accuracy',\n",
    "                                            patience=lr_patience,\n",
    "                                            factor=factor)\n",
    "# list of early_stop and lr\n",
    "callback_list = [early_stop, lr_reduction_on_plateau]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316b844",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Structure\n",
    "img_shape=(224,224,3)\n",
    "class_count = len(list(train_gen.class_indices.keys())) \n",
    "\n",
    "# efficientnetb3 from EfficientNet family is used for transfer learning\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')            #transfer learning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except for the last 80 layers\n",
    "# Upper 80 layers will be trained\n",
    "for layer in base_model.layers[:-80]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# stack layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    layers.BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    layers.Dense(256, kernel_regularizer= keras.regularizers.l2(l= 0.01), activity_regularizer= keras.regularizers.l1(0.001),\n",
    "                bias_regularizer= keras.regularizers.l1(0.001), activation= 'relu'),\n",
    "    layers.Dropout(rate= 0.4, seed= 42),\n",
    "    layers.Dense(class_count, activation= 'softmax')\n",
    "])\n",
    "\n",
    "# Adamax is used as an optimizer\n",
    "model.compile(keras.optimizers.Adamax(learning_rate= 0.0005), loss= 'categorical_crossentropy', metrics= ['accuracy'])       \n",
    "\n",
    "model.summary() # print summary of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6ea30",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f943f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x= train_gen, epochs= epochs, verbose=1, callbacks= callback_list,\n",
    "                    validation_data= valid_gen, validation_steps= None, shuffle= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c207723",
   "metadata": {},
   "source": [
    "# Create Functions to Display Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe3f76",
   "metadata": {},
   "source": [
    "Function to plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_history function: receives history of the trained model and creates a plot that \n",
    "# displays the accuray and loss history of the model by highlighting the best epoch for both metrics\n",
    "def plot_training_history(history_):               \n",
    "    # Define required variables\n",
    "    tr_acc = history_.history['accuracy']\n",
    "    tr_loss = history_.history['loss']\n",
    "    val_acc = history_.history['val_accuracy']\n",
    "    val_loss = history_.history['val_loss']\n",
    "    \n",
    "    min_loss_index = np.argmin(val_loss)\n",
    "    max_acc_index = np.argmax(val_acc)\n",
    "    val_lowest = val_loss[min_loss_index]\n",
    "    acc_highest = val_acc[max_acc_index]\n",
    "    \n",
    "    Epoch_numbers = [i+1 for i in range(len(tr_acc))]\n",
    "    \n",
    "    loss_label = f'best epoch= {str(min_loss_index + 1)}'\n",
    "    acc_label = f'best epoch= {str(max_acc_index + 1)}'\n",
    "\n",
    "    # Plot training history\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.lineplot(x=Epoch_numbers, y=tr_loss, color='g', label='Training loss')\n",
    "    sns.lineplot(x=Epoch_numbers, y=val_loss, color='b', label='Validation loss')\n",
    "    plt.scatter(min_loss_index + 1, val_lowest, s= 250, c= 'red', alpha=0.3, label= loss_label)\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.lineplot(x = Epoch_numbers,y = tr_acc, color='r', label='Training Accuracy')\n",
    "    sns.lineplot(x = Epoch_numbers, y = val_acc, color='g', label='Validation Accuracy')\n",
    "    plt.scatter(max_acc_index + 1 , acc_highest, s= 250, c= 'blue', alpha=0.3, label= acc_label)\n",
    "    plt.title('Training and Validation Accuracies')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Automatically adjust subplot parameters to give specified padding\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8392a",
   "metadata": {},
   "source": [
    "Function to plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb408dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(generator, y_true, y_pred):\n",
    "    sns.set_style('white')\n",
    "    # Get the class indices and labels\n",
    "    g_dict = generator.class_indices\n",
    "    classes = list(g_dict.keys())\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens, vmin=0, vmax=1) \n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # Normalize the confusion matrix\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    text_color = (0.5, 0.7, 0.5)\n",
    "\n",
    "    # Plot the normalized confusion matrix\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:.2f}\".format(cm_norm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=text_color)                \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698a223",
   "metadata": {},
   "source": [
    "Function to plot the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608267b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_report(y_true, y_pred, classes):\n",
    "    report = classification_report(y_true, y_pred, target_names=classes, output_dict=True)\n",
    "    report_df = report_df = pd.DataFrame(report)      \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(6, 15))\n",
    "    ax = sns.heatmap(report_df.iloc[:-1, :-3].T, cmap='Blues', annot=True, fmt='.2f', cbar=False)\n",
    "    ax.set_title('Classification Report')\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Classes')\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bf564",
   "metadata": {},
   "source": [
    "Function for visualizing model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ef76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is suited to test_generator that has batch_size of 8\n",
    "def visualize_predictions(test_generator, pred_generator):\n",
    "    # Create a list of 8 next predictions using generator\n",
    "    pred_values = []\n",
    "    for i in range(8):                                 \n",
    "        pred_values.append(next(pred_generator))\n",
    "    # Return classes, images to be displayed\n",
    "    g_dict = test_generator.class_indices        \n",
    "    classes = list(g_dict.keys())\n",
    "    images, labels = next(test_generator)\n",
    "    length = 8 # Specify length\n",
    "    plt.figure(figsize= (28, 12))\n",
    "    for i in range(length):\n",
    "        # Show image\n",
    "        plt.subplot(2, 4, (i + 1))\n",
    "        image = images[i] / 255 # Scale image pixels\n",
    "        plt.imshow(image)\n",
    "        # Get class of image\n",
    "        index_true = np.argmax(labels[i])  \n",
    "        class_name_true = classes[index_true] \n",
    "        class_name_pred = classes[pred_values[i]]\n",
    "        plt.title(f'Actual: {class_name_true}\\nPredicted: {class_name_pred}', color= 'purple', fontsize= 14)\n",
    "        plt.subplots_adjust(hspace=0.3, wspace=0.1)       \n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0dfbd",
   "metadata": {},
   "source": [
    "# Plot the Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abaf8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e01e24",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e158e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify dataframe length\n",
    "test_df_length = len(test_df)\n",
    "train_df_length = len(train_df)\n",
    "valid_df_length = len(valid_df)\n",
    "\n",
    "test_batch_size = 8 # set batch size to 8              \n",
    "test_steps = test_df_length // test_batch_size    \n",
    "train_steps = train_df_length // 32\n",
    "valid_steps = valid_df_length // 32\n",
    "\n",
    "# Evaluate scores\n",
    "train_score = model.evaluate(train_gen, steps= train_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= valid_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "# Print scores\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6d998",
   "metadata": {},
   "source": [
    "# Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e282382",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_gen.classes\n",
    "preds = model.predict(test_gen)       \n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "g_dict = test_gen.class_indices\n",
    "classes = list(g_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b27b1",
   "metadata": {},
   "source": [
    "# Plot Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d90737",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_report(y_true, y_pred, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc7f28",
   "metadata": {},
   "source": [
    "# Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_gen, y_true, y_pred)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506e10a",
   "metadata": {},
   "source": [
    "# Display Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.reset()\n",
    "pred_gen = (x for x in y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(test_gen, pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4078b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(test_gen, pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248dc12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(test_gen, pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87aa27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
